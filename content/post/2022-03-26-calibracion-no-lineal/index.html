---
title: Incertidumbre de una calibración no lineal con aplicación en química analítica
author:
date: '2020-06-06'
slug: incertidumbre-de-una-calibracion-no-lineal
categories: []
tags: []
subtitle: 'Método GUM y Monte Carlo -- Norma ISO 8466:2'
summary: ''
authors: []
lastmod: '2022-03-26T20:12:05-03:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>En un <a href="https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/">post anterior</a>
revisamos cómo estimar la incertidumbre de la concentración
de una muestra problema, cuando ésta ha sido obtenida interpolando la señal
instrumental en una curva de calibración lineal.</p>
<p>La expresión es relativamente simple y vimos también cómo podemos implementarla
en el lenguaje de programación <code>R</code> a través del package <code>chemCal</code>.</p>
<p>Sin embargo, la vida no es tan sencilla. Recoradará estimad@ lector@ que está
bastante documentada la presencia de desviaciones de la linealidad
a altas concentraciones, fenómeno muy conocido en los métodos
espectrofotométricos (Ley de Lambert-Beer). La severidad de estas desviaciones
varía en función del detector, el analito y otros factores físico-químicos
del sistema de medición.</p>
<p>Cuando existen estas desviaciones y deseamos llevar a cabo un
<a href="https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/">test de linealidad</a>,
es muy probable que el test rechace el modelo lineal, por lo tanto, no podemos
estimar la incertidumbre de calibración asumiendo este modelo. Si bien es cierto
podemos reducir el rango lineal y diluir la muestra problema que está fuera
del rango, la operación de dilución introduce nuevos errores (incluso errores
humanos de transcripción bastante frecuentes).</p>
<p>Una alternativa válida sería utilizar un modelo de calibración que capture esta
no linealidad evitando así la dilución de la muestra,
por lo tanto el problema se reduce a:</p>
<blockquote>
<p>¿Cómo estimar la incertidumbre de una muestra problema que ha sido
obtenida a través de una curva de calibración no lineal?</p>
</blockquote>
<p>Sin embargo, de esta pregunta se desprende al mismo tiempo otra interrogante:</p>
<blockquote>
<p>¿Cuál modelo de calibración no lineal utilizaré?</p>
</blockquote>
<p>Existen varios modelos de calibración no lineal:</p>
<ol style="list-style-type: decimal">
<li>Polinomios</li>
<li>New Rational (en realidad se llaman <em>aproximaciones de Padé</em>)</li>
<li>Splines</li>
<li>Loess</li>
<li>etc.</li>
</ol>
<p>Por lo tanto, no existe una respuesta completamente correcta desde
la prespectiva estadística, pues un modelo cuadrático sería tan válido como
un polinomio cúbico. Desde el punto de vista químico podríamos preguntarnos
¿qué sentido químico tiene una curva de calibración polinómica de grado 5?
¿Son interpretables los parámetros del modelo? En un modelo lineal como el
de Lambert-Beer: <span class="math inline">\(y = \beta_{0} + \beta_{1}x\)</span> la pendiente de la curva de
calibración tiene una interpretación química: es el producto entre coeficiente
de extinción molar y la longitud de la celda:</p>
<p><span class="math display" id="eq:lambert">\[
\underbrace{A}_\text{y} = \underbrace{\epsilon \cdot b}_\text{$\beta_{1}$} \cdot
\underbrace{C}_\text{x}
\tag{1}
\]</span>
Pero recuerde este sabio consejo de un monstruo de la estadística aplicada:</p>
<blockquote>
<p><em>“All models are wrong, but some are useful”</em>
– <cite>George Box</cite></p>
</blockquote>
<p>Por lo tanto, tenemos que tomar una decisión. Y obviamente, como soy el autor de
este humilde post, ya la tomé por Ud. En este artículo estimaremos la
incertidumbre de calibración de un modelo polinómico de grado 2, también
conocido como modelo cuadrático.</p>
<p>Nota: Desde el punto de vista <strong>estrictamente estadístico</strong> los modelos
polinómicos, como la calibración cuadrática, son también modelos lineales ya que
los coeficientes del modelo son lineales</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x + \beta_{2}x^2 + \epsilon\]</span></p>
<p>En cambio, en un modelo del tipo exponencial:</p>
<p><span class="math display">\[y = \beta_{0}\cdot e^{\beta_{1}x}\]</span></p>
<p>El coeficiente <span class="math inline">\(\beta_{1}\)</span> no es una función lineal.</p>
<div id="métodos-de-estimación-de-incertidumbre-de-calibración" class="section level1">
<h1>Métodos de estimación de incertidumbre de calibración</h1>
<p>En este post ejemplificaremos y compararemos tres métodos de estimación
de incertidumbre de calibración:</p>
<ol style="list-style-type: decimal">
<li><p>Norma ISO 8466-2:2001 <em>Water quality – Calibration and evaluation of
analytical methods and estimation of performance characteristics – Part 2:
Calibration strategy for non-linear second-order calibration functions.</em></p></li>
<li><p>Método GUM</p></li>
<li><p>Método de Monte Carlo (Suplemento 1 ISO-GUM)</p></li>
</ol>
<p>Implementaremos todos los métodos en el lenguaje de programación <code>R</code>, explicando
paso a paso el código fuente con el fin de que Ud. obtenga los mismos
resultados, es decir, un <strong>análisis reproducible</strong>.</p>
</div>
<div id="datos-de-calibración" class="section level1">
<h1>Datos de calibración</h1>
<p>Para ejemplificar los cálculos, utilizaremos los datos de calibración indicados
en el ejemplo de la sección 7 de la norma ISO 8466-2. El siguiente código <code>R</code>
nos permite ingresar los datos manualmente:</p>
<pre class="r"><code># Ingresamos los datos de calibración de la sección 7 de la norma ISO 8466-2
# x: concentración en mg/L
# y: Absorbancia [UA]

x &lt;- c(12, 18, 24, 30, 36, 42, 48, 54, 60, 66)
y &lt;- c(0.083, 0.123, 0.164, 0.203, 0.240, 0.273, 0.303, 0.334, 0.364, 0.393)

d &lt;- data.frame(x, y) # creamos un data frame con las variables x e y (esto es
                      # análogo a una matriz de datos en Excel con dos columnas)</code></pre>
<p>A continuación graficamos la curva de calibración con la librería <code>ggplot2</code>:</p>
<pre class="r"><code>library(ggplot2) # cargamos la librería ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 4.0.5</code></pre>
<pre class="r"><code>theme_set(theme_minimal()) # esto es sólo por una cuestión estética del gráfico

ggplot(d, aes(x = x, y = y)) +
  geom_point(color = &#39;red&#39;) +
  xlab(&#39;Concentración [mg/L]&#39;) +
  ylab(&#39;Absorbancia [UA]&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Mmm… no sé Ud. pero yo veo una leve curvatura.
Como lo vimos en un <a href="https://www.analytical.cl/post/como-demuestro-que-mi-curva-de-calibracion-es-lineal/">post anterior</a>
llevaremos a cabo un análisis estadístico básico para evaluar si el modelo de
calibración lineal es adecuado, o si nos inclinamos por la hipótesis de no
linealidad.</p>
<p>Como no tenemos replicados de cada punto de calibración, haremos un Test de
Linealidad de Mandel. Lo primero, es ajustar un modelo lineal a los datos
<span class="math inline">\(y = a + bx\)</span>:</p>
<pre class="r"><code>fit.lineal &lt;- lm(y ~ x, data = d) # ajustamos un modelo lineal y lo guardamos 
                                  # con el nombre fit.lineal

summary(fit.lineal) # para ver el análisis estadístico del ajuste</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = d)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.010636 -0.004720  0.001000  0.005727  0.009151 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.0250303  0.0058314   4.292  0.00264 ** 
## x           0.0057172  0.0001368  41.803 1.18e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.007453 on 8 degrees of freedom
## Multiple R-squared:  0.9954, Adjusted R-squared:  0.9949 
## F-statistic:  1747 on 1 and 8 DF,  p-value: 1.181e-10</code></pre>
<p>Esta tabla nos dice que el intercepto del modelo es
<span class="math inline">\(a = 0.0250303\)</span> y la pendiente <span class="math inline">\(b = 0.0057172\)</span>.
Note el alto coeficiente de determinación
<span class="math inline">\(r^{2} = 0.9954\)</span> lo cual indica que es un
buen modelo. El coeficiente de correlación es
<span class="math inline">\(r = 0.998\)</span> que si bien es un dato a
considerar, no es una prueba formal de linealidad.</p>
<p>La siguiente figura muestra el ajuste lineal sobre los datos de calibración:</p>
<pre class="r"><code>library(ggpmisc) # para escribir ecuaciones dentro del gráfico</code></pre>
<pre><code>## Warning: package &#39;ggpmisc&#39; was built under R version 4.0.4</code></pre>
<pre><code>## 
## Attaching package: &#39;ggpmisc&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     annotate</code></pre>
<pre class="r"><code>ggplot(d, aes(x = x, y = y)) +
  geom_point(color = &#39;red&#39;) +
  geom_smooth(method = &#39;lm&#39;, se = F, 
              size = 0.5) + # dibuja la curva de calibración lineal
  xlab(&#39;Concentración [mg/L]&#39;) +
  ylab(&#39;Absorbancia [UA]&#39;) +
  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), 
                                  sep = &quot;*\&quot;, \&quot;*&quot;)), 
               formula = y ~ x, 
               parse = TRUE, 
               rr.digits = 4)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot.lineal-1.png" width="672" /></p>
<p>Se observa que el ajuste lineal no es un buen modelo, pues no captura la
curvatura de los datos a pesar del alto coeficiente de correlación.
Esto se oberva más claramente si obervamos el gráfico
de residuos:</p>
<pre class="r"><code>plot(fit.lineal, which = 1, add.smooth = F, pch = 19, col = &#39;red&#39;, 
     main = &#39;Gráfico de residuos modelo lineal&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/fit.lin.res-1.png" width="672" /></p>
<p>La evidencia en contra del modelo lineal es abrumadora, el gráfico muestra
claramente un patrón en los residuos que indica que el modelo lineal
no es adecuado. Sin embargo, a pesar de la evidencia, haremos el Test de Mandel
para “comprobar” esta hipótesis. Para aplicar el Test de Mandel debemos ahora
ajustar el modelo cuadrático y compararlo con el modelo lineal.
Para ser consistentes en la notación de la
norma ISO 8466-2, definiremos el modelo de calibración cuadrático como:</p>
<p><span class="math display">\[ 
y = a + bx + cx^2
\]</span></p>
<pre class="r"><code>fit.nolineal &lt;- lm(y ~ x + I(x^2), data = d) # ajuste cuadrático y los guardamos 
                                          # con el nombre fit.nolineal
summary(fit.nolineal)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x + I(x^2), data = d)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -1.864e-03 -1.114e-03  6.818e-05  9.432e-04  1.939e-03 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -5.621e-03  2.475e-03  -2.271   0.0574 .  
## x            7.670e-03  1.420e-04  54.005 1.96e-10 ***
## I(x^2)      -2.504e-05  1.787e-06 -14.010 2.23e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.001479 on 7 degrees of freedom
## Multiple R-squared:  0.9998, Adjusted R-squared:  0.9998 
## F-statistic: 2.23e+04 on 2 and 7 DF,  p-value: 4.84e-14</code></pre>
<p>Se obtiene una tabla similar que la del modelo lineal, con la adición del
coeficiente que acompaña al
<span class="math inline">\(x^2\)</span>: <code>I(x^2)</code> <span class="math inline">\(= -2.504\times 10^{-5}\)</span>. Note
que el coeficiente de determinación del modelo cuadrático es mayor que el
del modelo lineal. Esto siempre se cumplirá, lo que hace el Test de Mandel es
discernir si esta “mejora” en el modelo es “significativa”.</p>
<p>La siguiente figura muestra el ajuste no lineal, el cual captura mucho mejor
la curvatura de los datos:</p>
<pre class="r"><code>ggplot(d, aes(x = x, y = y)) +
  geom_point(color = &#39;red&#39;) +
  geom_smooth(method = &#39;lm&#39;,         # dibuja la curva de calibración no lineal
              se = F, 
              formula = y ~ x + I(x^2), size = 0.5) + 
  xlab(&#39;Concentración [mg/L]&#39;) +
  ylab(&#39;Absorbancia [UA]&#39;) +
  stat_poly_eq(aes(label =  paste(stat(eq.label), stat(rr.label), 
                                  sep = &quot;*\&quot;, \&quot;*&quot;)),
               formula = y ~ x + I(x^2), 
               parse = TRUE, 
               rr.digits = 4)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot.nolineal-1.png" width="672" /></p>
<p>Ok, aplicamos
el Test de Mandel con el comando <code>anova</code>:</p>
<pre class="r"><code>anova(fit.lineal, fit.nolineal)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: y ~ x
## Model 2: y ~ x + I(x^2)
##   Res.Df        RSS Df  Sum of Sq      F    Pr(&gt;F)    
## 1      8 0.00044442                                   
## 2      7 0.00001530  1 0.00042912 196.29 2.235e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>El p-value del test de Mandel es <span class="math inline">\(2.23\times 10^{-6}\)</span>, el cual de acuerdo a
la interpretación tradicional, indica que el modelo lineal no es adecuado para
los datos de calibración.</p>
<p>Procedamos, entonces, a estimar la incertidumbre de la concentración <span class="math inline">\(\hat{x}\)</span>
de una muestra problema, cuyo valor fue obtenido interpolando la señal
instrumental en el modelo de calibración no lineal.</p>
<div id="estimación-de-incertidumbre-de-acuerdo-a-iso-8466-2" class="section level2">
<h2>Estimación de incertidumbre de acuerdo a ISO 8466-2</h2>
<p>Desde el punto de vista metrológico, la aproximación que indica esta norma es
similar a lo que dicta la guía ISO GUM clásica, es decir,
estima la incertidumbre a partir de un modelo de medición <span class="math inline">\(y = f(x)\)</span>.
La “gracia” de esta norma es que nos
ahorra tinta, pues la ecuación de incertidumbre ya está “algebraicamente
manipulada”. No entraremos en los detalles de las primeras secciones de la
norma los cuales estudian el comportamiento de la curvatura, es decir, si será
posible encontrar un máximo o un mínimo, lo cual es clave en la utilidad del
modelo cuadrático como función de calibración. Esto es
importante porque recuerde que una función parabólica tiene dos soluciones, si
existiera un máximo o un mínimo en el rango de trabajo, el modelo cuadrático no
puede ser utilizado como función de calibración.</p>
<p>La siguiente ecuación calcula la <strong>incertidumbre expandida</strong>
<span class="math inline">\(I(\hat{x}) = U_{\hat{x}}\)</span> de la concentración de la muestra problema <span class="math inline">\(\hat{x}\)</span>,
interpolada en la curva de calibración no lineal <span class="math inline">\(y = a + bx + cx^2\)</span>.
Corresponde a la ecuación (27) de la norma:</p>
<p><span class="math display">\[
I(\hat{x}) = \frac{s_{y} \cdot t_{n - 3,\, 95\%}}{b + 2c\hat{x}} \cdot
            \sqrt{\frac{1}{N} + \frac{1}{\hat{N}} + 
            \frac{(\hat{x} - \overline{x})^2 \, Q_{x^4} + 
            \left(\hat{x}^2 - \frac{\sum x_{i}^{2}}{N} \right)^2 Q_{xx} -
            2(\hat{x} - \overline{x}) 
            \left(\hat{x}^2 - \frac{\sum x_{i}^{2}}{N} \right) Q_{x^3}}
            {Q_{x^4} Q_{xx} - \left( Q_{x^3} \right)^2}}
\]</span></p>
<p>donde:</p>
<p><span class="math display">\[
s_{y} = \sqrt{\frac{\sum (y_{i} -\hat{y})^2}{N - 3}}
\]</span></p>
<ul>
<li><p><span class="math inline">\(y_{i}\)</span> es la respuesta experimental observada del estándar <span class="math inline">\(i\)</span>, <span class="math inline">\(\hat{y}\)</span> es la
respuesta instrumental que predice el modelo para el mismo estándar <span class="math inline">\(i\)</span>, por lo
tanto <span class="math inline">\(e_{i} = y_{i} - \hat{y}\)</span> es el residuo. <span class="math inline">\(N\)</span> es el número de calibrantes.
¿Por qué el denominador es <span class="math inline">\(N - 3\)</span> y no <span class="math inline">\(N -2\)</span> como en la calibración lineal?
Porque el modelo cuadrático posee tres parámetros <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> y <span class="math inline">\(c\)</span>.</p></li>
<li><p><span class="math inline">\(t_{N - 3,\, 95\%}\)</span> es el valor del T de Student con <span class="math inline">\(N - 3\)</span> grados de
libertad y un 95% de confianza.</p></li>
<li><p><span class="math inline">\(\hat{N}\)</span> es el número de replicados
independientes de la muestra problema. Como discutimos en
<a href="https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/">otro post</a>,
esto no corresponde a inyectar <span class="math inline">\(\hat{N}\)</span> veces la misma muestra en el
instrumento.</p></li>
<li><p><span class="math inline">\(\hat{x}\)</span> es la concentración de la muestra problema interpolada en la curva
de calibración no lineal, la cual se obtiene resolviendo la ecuación
cuadrática. Como Ud. recordará de sus años mozos esto siginifica que
la concentración interpolada se obtiene a partir de:</p></li>
</ul>
<p><span class="math display">\[\hat{x} = \frac{-b \pm \sqrt{b^2 - 4(a - y_{0})c}}{2c}\]</span>
donde <span class="math inline">\(y_{0}\)</span> es la señal instrumental de la muestra problema.</p>
<ul>
<li><p><span class="math inline">\(x_{i}\)</span> es la concentración del estándar <span class="math inline">\(i\)</span></p></li>
<li><p><span class="math inline">\(\overline{x} = \sum_{i = 1}^{N} x_{i}\)</span> es el promedio de las concentraciones
de los calibrantes.</p></li>
</ul>
<p>Finalmente:</p>
<p><span class="math display">\[
\begin{aligned}
Q_{xx}  &amp;= \sum x_{i}^2 - \frac{\left(\sum x_{i}\right)^2}{N} \\
Q_{x^3} &amp;= \sum x_{i}^3 - \left(\sum x_{i} \times \frac{\sum x_{i}^2}{N}\right) \\
Q_{x^4} &amp;= \sum x_{i}^4 - \frac{\left(\sum x_{i}^2\right)^2}{N}
\end{aligned}
\]</span></p>
<p>Ok, nada del otro mundo. Es bien fea, pero sólo son operaciones de aritmética
básica. Algunas observaciones:</p>
<p>Como Ud. recordará en el caso de la calibración lineal, a partir de esta
ecuación podemos inferir que si deseamos minimizar la incertidumbre de
calibración no lineal podemos :</p>
<ol style="list-style-type: decimal">
<li>Aumentar el número de calibrantes <span class="math inline">\(N\)</span></li>
<li>Aumentar el número de replicados independientes de la muestra problema <span class="math inline">\(\hat{N}\)</span></li>
<li>Aumentar la sensibilidad del método, que en el caso de la calibración
cuadrática está dada por <span class="math inline">\(b + 2c\hat{x}\)</span>, es decir, depende de la concentración
de la muestra problema <span class="math inline">\(\hat{x}\)</span>. En cambio, en la calibración lineal la
sensibilidad era constante en todo el rango de concentración estudiado y
correspondía a la pediente de la curva.</li>
</ol>
<p>En el caso de la calibración lineal, la incertidumbre de calibración se minimiza
en el centroide de la curva, en el caso del modelo cuadrático esto no siempre
es así. Observe en la siguiente figura las bandas de confianza de ambos tipos de
calibración:</p>
<pre><code>## Warning: package &#39;patchwork&#39; was built under R version 4.0.4</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/patch-1.png" width="672" /></p>
<p>Advierta que ambos modelos comparten la propiedad que la mayor incertidumbre se
encuentra en los extremos. Sin embargo, en la calibración cuadrática, para este
conjunto de datos, la menor incertidumbre no está en el centro de la curva.</p>
<p>Ok, a continuación implementaremos la ecuación de incertidumbre en <code>R</code> con los
datos del ejemplo de la sección 7 de la norma. La señal instrumental de la
muestra problema es <span class="math inline">\(y_{0} = 0.084\)</span> UA:</p>
<pre class="r"><code>N &lt;- length(x) # Número de calibrantes
N.hat &lt;- 1     # Número de replicados de la muestra problema
Qxx &lt;- sum(x^2) - sum(x)^2/N
Qx3 &lt;- sum(x^3) -(sum(x) * sum(x^2)/N)
Qx4 &lt;- sum(x^4) - sum(x^2)^2/N

a &lt;- fit.nolineal$coefficients[1]
b &lt;- fit.nolineal$coefficients[2]
c &lt;- fit.nolineal$coefficients[3]

s.y &lt;- summary(fit.nolineal)$sigma # Es lo que R denomina Residual standard error
t &lt;- qt(0.975, N - 3) # El T de Student (¡Ya no se usan tablas!)

y0 &lt;- 0.084 # Es la señal instrumental de la muestra problema
x.hat &lt;- (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c) # Concentración de la muestra

Ix &lt;- (s.y * t)/(b + 2*c*x.hat) * sqrt(
  1/N + 1/N.hat + ((x.hat - mean(x))^2*Qx4 + (x.hat^2 - sum(x^2)/N)^2 * Qxx -  
  2*(x.hat - mean(x))*(x.hat^2 - sum(x^2)/N)*Qx3)/
  (Qx4 * Qxx - Qx3^2)
)

Ix &lt;- unname(Ix) # Simplemente es para dejar sólo el número</code></pre>
<p>La concentración de la muestra es <span class="math inline">\(\hat{x} = 12.17\)</span> mg/L.
Al aplicar esta metodología obtenemos una incertidumbre expandida de
<span class="math inline">\(I(\hat{x}) = 0.63\)</span> mg/L, es decir, exactamente la misma que la que
indica la norma ISO. Note que si Ud. quisiera combinar esta incertidumbre de
calibración con algún otro factor (p.ej: masa de la muestra, volumen de aforo,
etc.) debe primero tansformarla en incertidumbre estándar, dividiéndola por el
factor de cobertura <span class="math inline">\(k\)</span>, que en este caso corresponde al t Student con <span class="math inline">\(N - 3\)</span>
grados de libertad al 95% de confianza (k = 2.36):</p>
<p><span class="math display">\[
u_{\hat{x}} = \frac{U_{\hat{x}}}{k} = 0.27\, \, \text{mg/L}
\]</span>
Por lo tanto, si tuviéramos que informar el resultado de la concentración
de la muestra interpolada en la curva de calibración no lineal informaríamos
<span class="math inline">\(12.17 \pm 0.63\)</span> mg/L [<em>nota mental: mmmm… esto de
las cifras significativas da para otro post, pero dejémoslo así por ahora.
No olvidar borrar este comentario.</em>]</p>
<p>¿Cómo varía esta incertidumbre de calibración no lineal con la concentración de
la muestra? La siguiente figura muestra esta variación:</p>
<pre class="r"><code>x &lt;- seq(12, 66, by = 6) # Rango de concentración
N &lt;- length(x)
N.hat &lt;- 1
mu.x &lt;- mean(x) # promedio de las concentraciones de los calibrantes
sq.x &lt;- sum(x^2) # suma de las concentraciones de los calibrantes al cuadrado
Qxx &lt;- sum(x^2) - sum(x)^2/N
Qx3 &lt;- sum(x^3) -(sum(x) * sum(x^2)/N)
Qx4 &lt;- sum(x^4) - sum(x^2)^2/N
t &lt;- qt(0.975, N - 3)

# Para graficar la incertidumbre vs concentración, primero debemos crear una
# función que tome un X (una concentración) y calcule el Y (incertidumbre)
Ux &lt;- function(x) {
    U &lt;- s.y*t/(b + 2*c*x) * sqrt(
    1/N + 1/N.hat + ((x - mu.x)^2*Qx4 + (x^2 - sq.x/N)^2 * Qxx -  
    2*(x - mu.x)*(x^2 - sq.x/N)*Qx3)/
    (Qx4 * Qxx - Qx3^2))
    return(unname(U))
}

# Graficamos concentración (X) vs Incertidumbre (Y)

plot(x, Ux(x), type = &#39;n&#39;,
     main = &#39;Concentración vs Incertidumbre de calibración&#39;,
     xlab = &#39;Concentración [mg/L]&#39;,
     ylab = &#39;Incertidumbre expandida [mg/L]&#39;)
lines(spline(x, Ux(x)), col = &#39;red&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/u.vs.con-1.png" width="672" />
Se aprecia que la incertidumbre aumenta con la concentración en una forma no
constante para concentraciones mayores a 20 mg/L.
Tal como mencionamos anteriormente, el mínimo no se encuentra en el
centro del rango de concentración como ocurre con la calibración lineal. Para
encontrar el valor exacto de concentración que minimiza la incertidumbre en este
rango, usamos el comando <code>optimize</code>:</p>
<pre class="r"><code># Busca el mínimo de la función Ux en el intervalo de 12 a 66 mg/L
optimize(Ux, interval = c(12, 66))</code></pre>
<pre><code>## $minimum
## [1] 20.29164
## 
## $objective
## [1] 0.5808116</code></pre>
<p>La concentración que minimiza la incertidumbre es
20.29 mg/L.</p>
<p>Muy entretenido, pero la vida es corta y debemos ser eficientes por lo tanto,
para evitarnos el “tedio” de implementar la fórmula a mano, utilizaremos
el package <code>investr</code> el cual calcula exactamente la incertidumbre de
calibración de un gran número de modelos de calibración, entre ellos, los
modelos cuadráticos:</p>
<pre class="r"><code># y0 es la señal de la muestra problema y0 = 0.084 UA
library(investr) # Cargamos la librería investr</code></pre>
<pre><code>## Warning: package &#39;investr&#39; was built under R version 4.0.4</code></pre>
<pre class="r"><code>x.hat &lt;- invest(fit.nolineal, data = d, y0 = y0, interval = &#39;Wald&#39;)
x.hat</code></pre>
<pre><code>##   estimate      lower      upper         se 
## 12.1672952 11.5400416 12.7945488  0.2652656</code></pre>
<p>donde:</p>
<ul>
<li><code>estimate</code> es la concentración de la muestra problema</li>
<li><code>upper</code> es el extremo superior de la incertidumbre expandida <span class="math inline">\(I(\hat{x})\)</span></li>
<li><code>lower</code> es el extremo inferior de la incertidumbre expandida <span class="math inline">\(I(\hat{x})\)</span></li>
<li><code>se</code> es la incertidumbre estándar de calibración <span class="math inline">\(u_{\hat{x}}\)</span>, la cual es
exactamente igual a la obtenida por la fórmula anterior
<span class="math inline">\(u_{\hat{x}} = \frac{U_{\hat{x}}}{k} = 0.27\, \, \text{mg/L}\)</span></li>
</ul>
<p>Note que si quisiéramos obener <span class="math inline">\(I(\hat{x})\)</span> a partir de esta tabla, tendríamos
que hacer la siguiente operación <span class="math inline">\(I(\hat{x}) =\)</span> <code>upper</code> - <code>estimate</code>:</p>
<pre class="r"><code>x.hat$upper - x.hat$estimate</code></pre>
<pre><code>## [1] 0.6272536</code></pre>
<p>No podemos usar el package <code>chemCal</code> que utilizamos
en un <a href="https://www.analytical.cl/post/como-calcular-la-incertidumbre-de-una-curva-de-calibracion/">post anterior</a>
para estimar la incertidumbre de calibración, porque este package sólo soporta
calibraciones lineales.</p>
</div>
<div id="estimación-de-incertidumbre-mediante-guía-iso-gum" class="section level2">
<h2>Estimación de incertidumbre mediante Guía ISO GUM</h2>
<p>Ya que la señal instrumental es una función de la concentración, entonces,
podemos utilizar la aproximación ISO GUM clásica para estimar la incertidumbre
de calibración. Por “clásica” me refiero a utilizar la aproximación de Taylor
con las derivadas parciales. Esta guía dice lo siguiente:</p>
<ol style="list-style-type: decimal">
<li>Expresar el mensurando como una ecuación de medición a través de una relación
funcional con las magnitudes de entrada. En este caso el mensurando es la
concentración <span class="math inline">\(\hat{x}\)</span> cuya ecuación de medición es la solución de la ecuación
cuadrática <span class="math inline">\(y_{0} = a + b\hat{x} + c\hat{x^2}\)</span> donde <span class="math inline">\(y_{0}\)</span> es la señal de la
muestra problema:</li>
</ol>
<p><span class="math display">\[
\hat{x} = \frac{-b \pm \sqrt{b^2 - 4(a - y_{0})c}}{2c}
\]</span>
2. Identificación de las fuentes de incertidumbre. Al observar la ecuación de
medición identificamos las siguientes fuentes de incertidumbre:</p>
<ul>
<li>Parámetros del modelo cuadrático: <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> y <span class="math inline">\(c\)</span></li>
<li>Señal instrumental de la muestra problema <span class="math inline">\(y_{0}\)</span></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Evaluación de las fuentes de incertidumbre:</li>
</ol>
<ul>
<li>Las incertidumbres estándar de los parámetros del modelo pueden ser obtenidas
directamente del ajuste cuadrático <code>fit.nolineal</code>:</li>
</ul>
<pre class="r"><code># parámetros del modelo
a &lt;- fit.nolineal$coeff[1]
b &lt;- fit.nolineal$coeff[2]
c &lt;- fit.nolineal$coeff[3]

# las incertidumbres estándar de a, b y c las obtenemos con la función summary
ua &lt;- summary(fit.nolineal)$coefficients[1, 2]
ub &lt;- summary(fit.nolineal)$coefficients[2, 2]
uc &lt;- summary(fit.nolineal)$coefficients[3, 2]</code></pre>
<ul>
<li>La incertidumbre estándar de la señal instrumental de la muestra problema
también puede obtenerse del ajuste cuadrático y corresponde a la
desviación estándar residual:</li>
</ul>
<pre class="r"><code>uy0 &lt;- summary(fit.nolineal)$sigma
y0 &lt;- 0.084 # dato del problema, es decir, la absorbancia de la muestra</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Determinación de la incertidumbre estándar combinada <span class="math inline">\(u_{\hat{x}}\)</span> a través
de la expresión:</li>
</ol>
<p><span class="math display">\[
u_{\hat{x}}^2 = \left( \frac{\partial{\hat{x}}}{\partial{y_{0}}}\right) ^{2} (u_{y_{0}})^{2} + 
\left( \frac{\partial{\hat{x}}}{\partial{a}}\right) ^{2} (u_{a})^{2} + 
\left( \frac{\partial{\hat{x}}}{\partial{b}}\right) ^{2} (u_{b})^{2} +
\left( \frac{\partial{\hat{x}}}{\partial{c}}\right )^{2} (u_{c})^{2}
\]</span></p>
<p>“sólo” nos falta obtener las derivadas parciales (aguante ese código <span class="math inline">\(\LaTeX\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial{\hat{x}}}{\partial{y_{0}}} &amp;= 
\frac{1}{\sqrt{b^{2} - 4c(a-y_{0})}} \\
\frac{\partial{\hat{x}}}{\partial{a}} &amp;=
  \frac{-1}{\sqrt{b^{2} - 4c(a-y_{0})}} \\
\frac{\partial{\hat{x}}}{\partial{b}} &amp;=
\frac{-1 + \frac{b}{\sqrt{b^{2} - 4c(a-y_{0})}}}{2c} \\
\frac{\partial{\hat{x}}}{\partial{c}} &amp;=
  \frac{-a + y_{0}}{c\sqrt{b^{2} - 4c(a-y_{0})}} - 
  \frac{-b + \sqrt{b^{2} - 4c(a-y_{0})}}{2c^{2}}
\end{aligned}
\]</span></p>
<p>¡Listo! ahora debemos evaluar las expresiones. Pero como soy flojo,
prefiero usar el excelente package <code>metRology</code> que hará todo el trabajo por
mí:</p>
<pre class="r"><code>library(metRology) # cargamos la librería</code></pre>
<pre><code>## 
## Attaching package: &#39;metRology&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     cbind, rbind</code></pre>
<pre class="r"><code>expr &lt;- expression((-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c)) # ecuación de medición
x &lt;- list(a = a, b = b, c = c, y0 = y0) # valores de cada X input
u &lt;- c(ua, ub, uc, uy0) # incertidumbres estándar de cada X input
u.GUM &lt;- uncert(expr, x, u, method = &#39;GUM&#39;) # Usamos el método GUM
u.GUM</code></pre>
<pre><code>## 
## Uncertainty evaluation
## 
## Call:
##   uncert.expression(obj = expr, x = x, u = u, method = &quot;GUM&quot;)
## 
## Expression: (-b + sqrt(b^2 - 4 * (a - y0) * c))/(2 * c)
## 
## Evaluation method:  GUM 
## 
## Uncertainty budget:
##    x             u            c           u.c        
## a  -5.621212e-03 2.474778e-03   -141.6217 -0.35048212
## b   7.670455e-03 1.420320e-04  -1723.1492 -0.24474238
## c  -2.504209e-05 1.787394e-06 -20966.0252 -0.03747454
## y0  8.400000e-02 1.478563e-03    141.6217  0.20939648
## 
##    y:  12.16727
## u(y):  0.4774807</code></pre>
<p>¿What? ¿Por qué obtuvimos una incertidumbre estándar de 0.477
y no la que calculamos con la ecuación de la norma ISO 0.265?
Por la sencilla razón de que los parámetros de un modelo cuadrático no son
independientes, sus covarianzas no son 0. Es más, algunas de las covarianzas
son negativas. Observe la siguiente figura que fue obtenida simulando
curvas de calibración cuadráticas. En la figura se muestra las correlaciones
entre los tres parámetros del modelo no lineal:</p>
<pre class="r"><code># Simularemos p = 200 curvas de calibración cuadráticas a partir de los datos 
# empíricos 

p &lt;- 200 # Número de simulaciones
a.sim &lt;- numeric(p) # vector que guardará el parámetro a
b.sim &lt;- numeric(p) # vector que guardará el parámetro b
c.sim &lt;- numeric(p) # vector que guardará el parámetro c

# Hacemos un loop
for(i in 1:p){
  x.sim &lt;- seq(12, 66, by = 6)
  y.sim &lt;- a + b*x.sim + c*x.sim^2 + rnorm(length(x.sim), 0, uy0)
  fit.nolineal.sim &lt;- lm(y.sim ~ x.sim + I(x.sim^2))
  a.sim[i] &lt;- fit.nolineal.sim$coeff[1]
  b.sim[i] &lt;- fit.nolineal.sim$coeff[2]
  c.sim[i] &lt;- fit.nolineal.sim$coeff[3]
}

# guardamos los parámetros simulados en un data frame que llamamos param.sim
param.sim &lt;- data.frame(a.sim, b.sim, c.sim) 
                                                
# graficamos los parámetros simulados
plot(param.sim)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Se advierte claramente que existe una correlación negativa entre los parámetros
<span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, además entre <span class="math inline">\(b\)</span> y <span class="math inline">\(c\)</span>. La correlación entre <span class="math inline">\(a\)</span> y <span class="math inline">\(c\)</span> es positiva.
En rigor, habría que incorporar las derivadas parciales cruzadas y las
covarianzas entre los parámetros. De sólo pensarlo, me dan ganas de
procastinar aún más la escritura de este post, así que recurriremos al
package <code>metRology</code>.</p>
<p>La parte “fácil” es obtener la matriz de covarianzas de los parámetros del
modelo con el comando <code>vcov</code>:</p>
<pre class="r"><code>v &lt;- vcov(fit.nolineal)
colnames(v) &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) # solo cosmética para que aparezcan los nombres
rownames(v) &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) # de los parámetros (es opcional)
v</code></pre>
<pre><code>##               a             b             c
## a  6.124524e-06 -3.337187e-07  3.910406e-09
## b -3.337187e-07  2.017310e-08 -2.491926e-10
## c  3.910406e-09 -2.491926e-10  3.194776e-12</code></pre>
<p>La diagonal de esta matriz es precisamente la incertidumbre estándar al
cuadrado de los parámetros (a.k.a sus varianzas). Si queremos, también podemos
expresarla como matriz de correlaciones con el comando <code>cov2cor</code>:</p>
<pre class="r"><code>param.cor &lt;- cov2cor(v)
param.cor</code></pre>
<pre><code>##            a          b          c
## a  1.0000000 -0.9494193  0.8840269
## b -0.9494193  1.0000000 -0.9815865
## c  0.8840269 -0.9815865  1.0000000</code></pre>
<p>En la diagonal de esta matriz obviamente esperamos correlación 1. Se observa
claramente la alta correlación entre los parámetros, como dijimos anteriormente,
algunas de ellas son negativas.</p>
<p>La parte “difícil” es que debemos incorporar la variable señal
instrumental de la muestra problema <span class="math inline">\(y_{0}\)</span>, la cual obviamente es independiente
de los parámetros del modelo:</p>
<pre class="r"><code># Incorporamos la variable y0 que es independiente de los parámetros
v &lt;- rbind(v, y0 = rep(0, 3)) 
v &lt;- cbind(v, y0 = rep(0, 4))
v[4, 4] &lt;- uy0^2 # Asignamos al elemento de la 4a fila y 4a columna  
                 # la varianza de y0
v</code></pre>
<pre><code>##                a             b             c           y0
## a   6.124524e-06 -3.337187e-07  3.910406e-09 0.000000e+00
## b  -3.337187e-07  2.017310e-08 -2.491926e-10 0.000000e+00
## c   3.910406e-09 -2.491926e-10  3.194776e-12 0.000000e+00
## y0  0.000000e+00  0.000000e+00  0.000000e+00 2.186147e-06</code></pre>
<p>Ahora, incorporamos las covarianzas en el cálculo por método GUM:</p>
<pre class="r"><code>u.GUM.cov &lt;- uncert(expr, x, cov = v, method = &quot;GUM&quot;)
u.GUM.cov</code></pre>
<pre><code>## 
## Uncertainty evaluation
## 
## Call:
##   uncert.expression(obj = expr, x = x, method = &quot;GUM&quot;, cov = v)
## 
## Expression: (-b + sqrt(b^2 - 4 * (a - y0) * c))/(2 * c)
## 
## Evaluation method:  GUM 
## 
## Uncertainty budget:
##    x             u            c           u.c        
## a  -5.621212e-03 2.474778e-03   -141.6217 -0.35048212
## b   7.670455e-03 1.420320e-04  -1723.1492 -0.24474238
## c  -2.504209e-05 1.787394e-06 -20966.0252 -0.03747454
## y0  8.400000e-02 1.478563e-03    141.6217  0.20939648
## 
##    y:  12.16727
## u(y):  0.2651904</code></pre>
<p>¡Perfecto!, ahora sí, al incluir las covarianzas obtenemos resultados consistentes
con el método descrito en la norma ISO 8466-2.</p>
</div>
<div id="estimación-con-el-método-de-monte-carlo" class="section level2">
<h2>Estimación con el Método de Monte Carlo</h2>
<p>No detallaremos aquí cómo funciona el método de Monte Carlo, puede consultarlo
en <a href="https://www.analytical.cl/post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo/">este post</a> y en
<a href="https://www.analytical.cl/post/validacion-calculos-incertidumbre-quimica-analitica-metodo-monte-carlo-parte2/">este otro</a>.</p>
<p>Sería super simple si usamos el package <code>metRology</code>, el problema es que el
package lanza un error numérico cuando existen covarianzas negativas. Probé
el ejemplo que incluye el manual de <code>metRology</code> y el error se repite. Es un
problema al evaluar la suma de las correlaciones. Le
consulté al autor Steve Ellison, sin embargo, a la fecha (09 de junio 2020)
aún no tengo respuesta, a pesar de que Steve siempre responde las consultas en
forma muy expedita. Otros usuarios han tenido un problema similar y se ha
abierto un hilo en <a href="https://stackoverflow.com/questions/60971950/error-in-eigensigma-symmetric-true-0-x-0-matrix-in-metrology-uncertmc-wit/62119518#62119518">stackoverflow</a>.</p>
<p>Por lo tanto, implementamos el método de Monte Carlo “a mano” utilizando el
package <code>MASS</code> el cual permite generar muestras aleatorias multivariadas
incluyendo las correlaciones:</p>
<pre class="r"><code># No funciona metRology MC así que lo hicimos a mano
library(MASS) # cargamos la librería</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:patchwork&#39;:
## 
##     area</code></pre>
<pre class="r"><code># Generamos n muestras aleatorias multivariadas, cuyas medias 
# corresponden a los valores de a, b, c e y0
# La matriz de covarianza Sigma = v la calculamos anteriormente

set.seed(123) # Para que Ud. obtenga los mismos resultados
muestra.MC &lt;- mvrnorm(n = 10000, mu = c(a, b, c, y0), Sigma = v, empirical = T)
colnames(muestra.MC) &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;y0&#39;) # solo cosmética
muestra.MC &lt;- data.frame(muestra.MC) # lo guardamos como data.frame
head(muestra.MC) # muestra las primeras n = 6 simulaciones</code></pre>
<pre><code>##              a           b             c         y0
## 1 -0.004872147 0.007615757 -2.422806e-05 0.08771566
## 2 -0.004584974 0.007614935 -2.439880e-05 0.08385741
## 3 -0.005903886 0.007685426 -2.569142e-05 0.08643112
## 4 -0.004770996 0.007561121 -2.367442e-05 0.08417975
## 5 -0.003113309 0.007559284 -2.403774e-05 0.08478106
## 6 -0.006100136 0.007724920 -2.626908e-05 0.08644533</code></pre>
<p>Cada fila es una simulación. Si, por ejemplo, calculamos el promedio de cada
variable simulada, obtenemos un valor similar a los valores empíricos. A mayor
número de simulaciones, más nos acercamos a valores que asumimos como
verdaderos.</p>
<pre class="r"><code>apply(muestra.MC, 2, mean) # promedio de cada columna</code></pre>
<pre><code>##             a             b             c            y0 
## -5.621212e-03  7.670455e-03 -2.504209e-05  8.400000e-02</code></pre>
<p>Bien, lo que tenemos que hacer es que en cada simulación debemos
calcular la concentración de la muestra:</p>
<pre class="r"><code># cargaré estas librerías sólo para facilitar la manipulación de los datos
library(magrittr)
library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## v tibble  3.1.5     v dplyr   1.0.7
## v tidyr   1.1.4     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.1
## v purrr   0.3.4</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;forcats&#39; was built under R version 4.0.4</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x ggpmisc::annotate() masks ggplot2::annotate()
## x tidyr::extract()    masks magrittr::extract()
## x dplyr::filter()     masks stats::filter()
## x dplyr::lag()        masks stats::lag()
## x dplyr::select()     masks MASS::select()
## x purrr::set_names()  masks magrittr::set_names()</code></pre>
<pre class="r"><code># Creamos una nueva variable llamada x.hat que corresponde a la concentración de
# la muestra
muestra.MC &lt;- muestra.MC %&gt;% 
  mutate(x.hat = (-b + sqrt(b^2 - 4*(a - y0)*c))/(2*c))
head(muestra.MC) # muestra las primeras n = 6 simulaciones</code></pre>
<pre><code>##              a           b             c         y0    x.hat
## 1 -0.004872147 0.007615757 -2.422806e-05 0.08771566 12.66792
## 2 -0.004584974 0.007614935 -2.439880e-05 0.08385741 12.08205
## 3 -0.005903886 0.007685426 -2.569142e-05 0.08643112 12.53997
## 4 -0.004770996 0.007561121 -2.367442e-05 0.08417975 12.23276
## 5 -0.003113309 0.007559284 -2.403774e-05 0.08478106 12.09232
## 6 -0.006100136 0.007724920 -2.626908e-05 0.08644533 12.51252</code></pre>
<p>La última columna corresponde a la concentración calculada para cada
simulación. Por lo tanto, si queremos obtener la incertidumbre estándar de
la concentración, basta calcular la desviación estándar de esa columna:</p>
<pre class="r"><code>mu.x.hat.MC &lt;- mean(muestra.MC$x.hat) # valor promedio de concentración
u.x.hat.MC &lt;- sd(muestra.MC$x.hat) # incertidumbre estándar de la concentración
u.x.hat.MC</code></pre>
<pre><code>## [1] 0.265321</code></pre>
<p>Se obtiene una incertidumbre estándar de calibración de
0.265 mg/L, la
cual es consistente con los otros métodos estudiados. La siguiente
figura muestra el histograma de las concentraciones simuladas:</p>
<pre class="r"><code>hist(muestra.MC$x.hat, 
     breaks = 20,
     main = &#39;Concentraciones simuladas por Monte Carlo&#39;,
     xlab = &#39;Concentración [mg/L]&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plot.u.MC-1.png" width="672" /></p>
<p>Finalmente, la siguiente tabla resume los resultados de los tres métodos
considerando la incertidumbre estándar de calibración:</p>
<pre class="r"><code>tabla &lt;- data.frame(Ix/t, u.GUM$u.y, u.GUM.cov$u.y, u.x.hat.MC)
knitr::kable(tabla, 
             rownames = NA,
             col.names = c(&#39;ISO&#39;, &#39;GUM&#39;, &#39;GUM/Covarianzas&#39;, &#39;Monte Carlo&#39;),
             align = &#39;l&#39;)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">ISO</th>
<th align="left">GUM</th>
<th align="left">GUM/Covarianzas</th>
<th align="left">Monte Carlo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.2651904</td>
<td align="left">0.4774807</td>
<td align="left">0.2651904</td>
<td align="left">0.265321</td>
</tr>
</tbody>
</table>
<p>Se aprecia claramente una excelente concordancia entre los tres métodos.
Sin embargo, para que el método GUM entregue resultados correctos, es necesario
incorporar las covarianzas entre las variables input.</p>
<p>En un próximo post exploraremos el método <em>Bootstrap</em>, un método estadístico
por excelencia para estimar incertidumbre sin utilizar un modelo de medición…</p>
<blockquote>
<p>¡Dejad que los datos hablen!</p>
</blockquote>
</div>
</div>
<div id="bibliografía" class="section level1">
<h1>Bibliografía</h1>
<ol style="list-style-type: decimal">
<li><p>Norma ISO 8466-2:2001 <em>Water quality – Calibration and evaluation of
analytical methods and estimation of performance characteristics – Part 2:
Calibration strategy for non-linear second-order calibration functions.</em></p></li>
<li><p>Brandon M. Greenwell and Christine M. Schubert Kabban (2014). investr: An R
Package for Inverse Estimation. The R Journal, 6(1), 90-100. URL <a href="http://journal.r-project.org/archive/2014-1/greenwell-kabban.pdf" class="uri">http://journal.r-project.org/archive/2014-1/greenwell-kabban.pdf</a>.</p></li>
<li><p>NIST/SEMATECH e-Handbook of Statistical Methods,
<em>Uncertainty for quadratic calibration using propagation of error</em>,
<a href="https://www.itl.nist.gov/div898/handbook/mpc/section3/mpc3671.htm" class="uri">https://www.itl.nist.gov/div898/handbook/mpc/section3/mpc3671.htm</a>,
09 de junio 2020.</p></li>
<li><p>Nonlinear multivariate calibration methods in analytical chemistry
Sonja Sekulic, Mary Beth Seasholtz, Ziyi Wang, Bruce R. Kowalski, Samuel E.
Lee, and Bradley R. Holt <em>Analytical Chemistry 1993 65 (19), 835A-845A</em></p></li>
</ol>
</div>
